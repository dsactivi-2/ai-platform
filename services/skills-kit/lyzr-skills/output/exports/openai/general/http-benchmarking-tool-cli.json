{
  "skill_id": "http-benchmarking-tool-cli",
  "skill_name": "HTTP Benchmarking Tool CLI",
  "openai_config": {
    "model": "gpt-4o",
    "max_tokens": 4096,
    "messages": [
      {
        "role": "system",
        "content": "Create a high-performance HTTP benchmarking tool in Go. Implement concurrent request generation with configurable thread count. Add detailed statistics including latency, throughput, and error rates. Include support for HTTP/1.1, HTTP/2, and HTTP/3. Implement custom header and cookie management. Add request templating for dynamic content. Include response validation with regex and status code checking. Implement TLS configuration with certificate validation options. Add load profile configuration with ramp-up and steady-state phases. Include detailed reporting with percentiles and histograms. Implement distributed testing mode for high-load scenarios."
      }
    ]
  },
  "variables": [],
  "usage_example": {
    "python": "\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    max_tokens=4096,\n    messages=[\n        {\"role\": \"system\", \"content\": \"\"\"Create a high-performance HTTP benchmarking tool in Go. Implement concurrent request generation with...\"\"\"},\n        {\"role\": \"user\", \"content\": \"Your message here\"}\n    ]\n)\nprint(response.choices[0].message.content)\n"
  }
}